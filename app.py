import os
import uuid
import re
import requests
import streamlit as st
from dotenv import load_dotenv
from gtts import gTTS
from pdf2image import convert_from_bytes
import datetime
from camel_agents import MedicalReportAssistant
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib import colors
from reportlab.lib.units import inch
import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.preprocessing import StandardScaler, LabelEncoder
import threading
import time
from PIL import Image
import tensorflow as tf



# ---------------- TELEGRAM MESSAGE FUNCTION ----------------
def send_telegram_message(message, chat_id, bot_token):
    """Send a Telegram message using the Bot API."""
    try:
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        payload = {"chat_id": chat_id, "text": message}
        response = requests.post(url, json=payload)
        if response.status_code == 200:
            print(f"‚úÖ Telegram message sent: {message}")
        else:
            print(f"‚ö†Ô∏è Telegram error: {response.text}")
    except Exception as e:
        print("‚ö†Ô∏è Error sending Telegram message:", e)


# ---------------- PDF GENERATOR ----------------
def generate_pdf(summary_text, medicine_text, output_path="MedScope_Report.pdf"):
    """Generate a formatted PDF report containing summary and medicine suggestions."""
    c = canvas.Canvas(output_path, pagesize=A4)
    width, height = A4

    c.setFont("Helvetica-Bold", 18)
    c.setFillColor(colors.HexColor("#0072ff"))
    c.drawString(1 * inch, height - 1 * inch, "ü©∫ MedScope AI Analysis Report")

    c.setStrokeColor(colors.HexColor("#00c6ff"))
    c.setLineWidth(2)
    c.line(1 * inch, height - 1.1 * inch, width - 1 * inch, height - 1.1 * inch)

    c.setFont("Helvetica-Bold", 14)
    c.setFillColor(colors.black)
    c.drawString(1 * inch, height - 1.5 * inch, "Doctor‚Äôs AI Opinion:")
    text_obj = c.beginText(1 * inch, height - 1.8 * inch)
    text_obj.setFont("Helvetica", 11)
    for line in summary_text.split("\n"):
        text_obj.textLine(line.strip())
    c.drawText(text_obj)

    y_position = text_obj.getY() - 0.5 * inch
    c.setFont("Helvetica-Bold", 14)
    c.drawString(1 * inch, y_position, "üíä Recommended Medicines:")
    text_obj2 = c.beginText(1 * inch, y_position - 0.3 * inch)
    text_obj2.setFont("Helvetica", 11)
    for line in medicine_text.split("\n"):
        text_obj2.textLine(line.strip())
    c.drawText(text_obj2)

    y_position2 = text_obj2.getY() - 0.5 * inch
    c.setFont("Helvetica-Oblique", 10)
    c.setFillColor(colors.grey)
    c.drawString(1 * inch, y_position2,
                 "‚ö†Ô∏è This report is for informational purposes only. Consult a doctor before taking any medication.")
    c.setFont("Helvetica", 9)
    c.drawCentredString(width / 2, 0.5 * inch, "Generated by MedScope AI | ¬© 2025")

    c.save()
    return output_path


# ---------------- ENV & PAGE SETUP ----------------
load_dotenv("api.env")
st.set_page_config(page_title="MedScope AI ‚ö°", page_icon="‚öïÔ∏è", layout="wide")

# ---------------- FILE UPLOAD STATE ----------------
if "uploaded_file" not in st.session_state:
    st.session_state.uploaded_file = None
if "file_bytes" not in st.session_state:
    st.session_state.file_bytes = None


def clear_file():
    st.session_state.uploaded_file = None
    st.session_state.file_bytes = None


st.session_state.clear_file = clear_file

# ---------------- PAGE HEADER ----------------
st.markdown("""
<div style='text-align:center; margin-top:2rem;'>
  <h1 style='background:linear-gradient(90deg,#00c6ff,#0072ff);-webkit-background-clip:text;-webkit-text-fill-color:transparent;'>‚ö° MedScope AI ‚ö°</h1>
  <p style='color:#b0bec5;'>Empowering healthcare with intelligent insights.</p>
</div>
""", unsafe_allow_html=True)

# ---------------- LOAD MODEL ----------------
@st.cache_resource
def load_disease_model():
    df = pd.read_csv(r"c:\\Users\\Admin\\Downloads\\merged_medical_dataset.csv")
    le = LabelEncoder()
    df["Disease_encoded"] = le.fit_transform(df["Disease"])
    X = df.select_dtypes(include=["number"])
    y = df["Disease_encoded"]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    num_classes = len(np.unique(y))
    model = Sequential([
        Dense(128, activation='relu', input_dim=X_scaled.shape[1]),
        Dropout(0.3),
        Dense(64, activation='relu'),
        Dropout(0.3),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    model.fit(X_scaled, y, epochs=25, batch_size=32, verbose=0)
    return model, scaler, le, X.columns.tolist()


model, scaler, label_encoder, feature_names = load_disease_model()
# ---------------- CHEST X-RAY MODEL LOADER ----------------
@st.cache_resource
def load_chest_model():
    model_path = r"D:\MedScope_Vision\models\ChestVisionNet.h5"   # <-- adjust if different
    model = tf.keras.models.load_model(model_path)
    return model

CHEST_IMG_SIZE = (150, 150)
   # must match what you used in training
CHEST_CLASS_LABELS = ["Normal", "Pneumonia"]  # change if you trained more classes

chest_model = load_chest_model()


# ---------------- SIDEBAR UPLOAD ----------------
with st.sidebar:
    st.subheader("üìÅ Upload Medical Report")
    uploaded = st.file_uploader("", type=["pdf"], label_visibility="collapsed")
    if uploaded:
        st.session_state.uploaded_file = uploaded
        st.session_state.file_bytes = uploaded.getbuffer()
        st.button("üóëÔ∏è Clear Uploaded File", on_click=st.session_state.clear_file)
        st.success("‚úÖ File uploaded successfully!")


# ---------------- UTILITY FUNCTIONS ----------------
def clean_text(text):
    return re.sub(r"[^\w\s]", "", text)


def generate_audio(text):
    audio_path = "temp_result_audio.mp3"
    gTTS(text=clean_text(text), lang="en").save(audio_path)
    return audio_path

def groq_explain_chest(label: str, confidence: float) -> str:
    """Use Groq LLM to explain the CNN result with causes, actions, and precautions."""
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        return "‚ö†Ô∏è GROQ_API_KEY missing in api.env. Add GROQ_API_KEY=your_key and restart the app."

    prompt = f"""
    You are a medical AI assistant. A chest X-ray model predicted: **{label}** with confidence {confidence:.2f}%.
    Please explain in simple patient-friendly language:
    1) What this finding means.
    2) Common causes and when to worry.
    3) Immediate steps/lifestyle tips.
    4) What to avoid and key precautions.
    Keep it under 220 words; use short bullet points where helpful. End with: 'Consult a clinician for confirmation.'
    """

    try:
        resp = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
            json={
                "model": "llama-3.1-8b-instant",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 320,
                "temperature": 0.5
            },
            timeout=30
        )
        if resp.status_code == 200:
            return resp.json()["choices"][0]["message"]["content"].strip()
        else:
            return f"‚ö†Ô∏è Groq API error: {resp.text}"
    except Exception as e:
        return f"‚ö†Ô∏è Groq request failed: {e}"

# ---------------- TABS ----------------
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "Analyze Report", "‚ÑπÔ∏è About", "üß† Disease Prediction", "üíä Medication Reminder", "ü©ª Chest X-ray Analysis"
])


# ---------------- TAB 4: REMINDER ----------------
reminder_file = "reminders.csv"

with tab4:
    st.header("üíä Weekly Medication Scheduler")
    st.markdown("Plan your medicines for the week and get Telegram reminders automatically!")

    with st.form("reminder_form"):
        col1, col2 = st.columns(2)
        with col1:
            medicine = st.text_input("Medicine Name", placeholder="e.g. Metformin")
        with col2:
            dosage = st.text_input("Dosage", placeholder="e.g. 500mg")

        st.markdown("### üóìÔ∏è Select Days")
        days = {d: st.checkbox(d) for d in
                ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]}

        st.markdown("### üïê Select Time")
        time_options = {
            "Morning (8:00 AM)": st.checkbox("Morning (8:00 AM)"),
            "Afternoon (1:00 PM)": st.checkbox("Afternoon (1:00 PM)"),
            "Night (8:00 PM)": st.checkbox("Night (8:00 PM)"),
        }

        include_custom = st.checkbox("‚è∞ Include Custom Time")
        custom_time_value = st.time_input("Select Custom Time", value=datetime.time(9, 30), step=60)

        phone = st.text_input("WhatsApp Number (with country code)", placeholder="+91XXXXXXXXXX")

        submit = st.form_submit_button("üíæ Save Reminder")

        if submit:
            selected_days = [d for d, v in days.items() if v]
            selected_times = []
            for label, sel in time_options.items():
                if sel:
                    if "Morning" in label: selected_times.append("08:00")
                    elif "Afternoon" in label: selected_times.append("13:00")
                    elif "Night" in label: selected_times.append("20:00")
            if include_custom:
                selected_times.append(custom_time_value.strftime("%H:%M"))

            if not medicine or not dosage or not selected_days or not selected_times:
                st.warning("‚ö†Ô∏è Please fill all fields correctly.")
            else:
                entries = []
                for day in selected_days:
                    for time_val in selected_times:
                        entries.append({
                            "Medicine": medicine,
                            "Dosage": dosage,
                            "Day": day,
                            "Time": time_val,
                            "Phone": phone,
                            "Added_On": datetime.date.today()
                        })
                df_entry = pd.DataFrame(entries)
                if os.path.exists(reminder_file):
                    df_old = pd.read_csv(reminder_file)
                    df_combined = pd.concat([df_old, df_entry], ignore_index=True)
                    df_combined.to_csv(reminder_file, index=False)
                else:
                    df_entry.to_csv(reminder_file, index=False)

                st.success(f"‚úÖ Reminder added for {medicine} ({dosage}) at {', '.join(selected_times)}")

                BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
                CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
                if BOT_TOKEN and CHAT_ID:
                    msg = f"üíä New Reminder Added!\n{medicine} ({dosage}) on {', '.join(selected_days)} at {', '.join(selected_times)}"
                    send_telegram_message(msg, CHAT_ID, BOT_TOKEN)
                else:
                    st.warning("‚ö†Ô∏è Telegram bot not configured. Please check api.env.")

    st.markdown("---")
    st.subheader("üìã Active Reminders")
    if os.path.exists(reminder_file):
        df = pd.read_csv(reminder_file)
        st.dataframe(df, use_container_width=True)
        if st.button("üóëÔ∏è Clear All Reminders"):
            os.remove(reminder_file)
            st.success("‚úÖ All reminders cleared.")
    else:
        st.info("No reminders yet.")


# ---------------- REMINDER SCHEDULER ----------------
def start_reminder_scheduler():
    """Run a background thread to check reminders every 60 seconds and send Telegram alerts."""
    if "scheduler_running" in st.session_state and st.session_state.scheduler_running:
        return

    def check_loop():
        load_dotenv("api.env")
        BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
        CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
        print("‚úÖ Reminder Scheduler Started")
        while True:
            now = datetime.datetime.now()
            current_day = now.strftime("%A")
            current_time = now.strftime("%H:%M")
            if os.path.exists(reminder_file):
                try:
                    df = pd.read_csv(reminder_file)
                    for _, row in df.iterrows():
                        day = str(row["Day"]).strip()
                        time_val = str(row["Time"]).strip().zfill(5)
                        med = str(row["Medicine"]).strip()
                        dose = str(row["Dosage"]).strip()
                        if day == current_day and time_val == current_time:
                            msg = f"üíä Reminder: Take {med} ({dose}) now!"
                            send_telegram_message(msg, CHAT_ID, BOT_TOKEN)
                            print(f"üîî Reminder triggered for {med} at {current_time}")
                except Exception as e:
                    print("‚ö†Ô∏è Error checking reminders:", e)
            time.sleep(60)

    thread = threading.Thread(target=check_loop, daemon=True)
    thread.start()
    st.session_state.scheduler_running = True


# ‚úÖ Start scheduler automatically when app loads
start_reminder_scheduler()

# ---------------- TAB 5: CHEST X-RAY ANALYSIS ----------------
# ---------------- TAB 5: CHEST X-RAY ANALYSIS ----------------
with tab5:
    st.header("ü©ª Chest X-ray AI Diagnosis")
    st.markdown("""
    Upload a **Chest X-ray image** (JPG/PNG).  
    The AI model predicts whether it‚Äôs **Normal** or **Pneumonia**,  
    and then Groq AI explains the condition in simple, patient-friendly terms.
    """)

    upload_xray = st.file_uploader("üì§ Upload Chest X-ray", type=["jpg", "jpeg", "png"])

    if upload_xray is not None:
        # Step 1: Show uploaded image
        st.image(upload_xray, caption="üì∏ Uploaded X-ray", use_container_width=True)

        try:
            # Step 2: CNN Preprocessing
            img = Image.open(upload_xray).convert("RGB")     # 3-channel color
            img_resized = img.resize((150, 150))             # match model training size
            x = np.array(img_resized, dtype=np.float32) / 255.0
            x = np.expand_dims(x, axis=0)                    # shape (1,150,150,3)

            # Debug info (for logs)
            print("üìè Input shape for model:", x.shape)
            print("üìê Model expects:", chest_model.input_shape)

            # Step 3: Model Prediction
            with st.spinner("üîé Analyzing X-ray using CNN model..."):
                probs = chest_model.predict(x)

            pred_idx = int(np.argmax(probs[0]))
            confidence = float(np.max(probs[0])) * 100.0
            label = CHEST_CLASS_LABELS[pred_idx] if pred_idx < len(CHEST_CLASS_LABELS) else f"Class {pred_idx}"

            # Step 4: Display Prediction
            st.success(f"‚úÖ Detected Condition: **{label}**")
            st.info(f"üìä Model Confidence: **{confidence:.2f}%**")

            # Step 5: Generate AI Explanation using Groq
            with st.spinner("üß† Generating AI explanation & medical guidance..."):
                explain = groq_explain_chest(label, confidence)
            st.markdown("### ü©∫ AI Doctor‚Äôs Explanation")
            st.markdown(explain)

            # Step 6 (Optional): Grad-CAM visualization placeholder
            with st.expander("üß¨ View AI Attention Map (Grad-CAM)"):
                st.markdown("This feature highlights where the CNN focused while making its decision.")
                st.markdown("_Coming soon ‚Äî will visualize heatmap regions on the X-ray._")

        except Exception as e:
            st.error(f"‚ö†Ô∏è Error processing image: {e}")
